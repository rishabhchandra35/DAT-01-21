{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: KFold, Regularization, & Pipelines\n",
    "\n",
    "Welcome!  This lab is going to introduce us to some very important aspects of data processing and model building.  \n",
    "\n",
    "Specifically, it's going to go over the following:\n",
    "\n",
    " - **KFold Cross Validation:** This is a more thorough way of choosing your validation set to give you a better idea of how your model might perform under various circumstances within your training data.\n",
    " - **Regularization:** This is an evergreen technique for dealing with models that are overfit (ie, higher scores on training vs. test data).  Regularized linear models are often much better prepared to handle messy data & outliers when using this technique.\n",
    " - **Pipelines:** (Time permitting!) This is an underappreciated aspect of the Scikit-Learn api that allows you to chain together multiple data processing steps, making it much easier to test different models and work seamlessly between your training & test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This lab builds off of the one performed in the last class.  As such, it might be easier just to keep working in your previous lab to answer these questions.  It assumes you already have your data processed from the iowa housing lab.  \n",
    "\n",
    "The questions are listed here just to make the separation of concerns easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How Does Your Validation Score Differ Using KFold Cross Validation?\n",
    "\n",
    "Take a look at the validation score you got from your previous exercise.  \n",
    "\n",
    "This time, run your model through KFold cross validation using `cross_val_score`.  Is your total validation score appreciably different?  What were your highest and lowest values?\n",
    "\n",
    "What if you changed your number of folds?  Try using 5, 10, & 25 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Updating Your Model With Ridge & Lasso Regression\n",
    "\n",
    "Instead of using Linear Regression, import `Ridge` and `Lasso`, and use cross validation to find the ideal value of alpha.  \n",
    "\n",
    "Some basic tips:\n",
    "\n",
    "For values of alpha try this:  `alphas = np.logspace(-4, 4, 9)`\n",
    "Then write a `for-loop` that generically goes like this:\n",
    "\n",
    "`for value in alphas:\n",
    "    1). set value of alpha to current value using set_params() method\n",
    "    2). pass in instance of Ridge or Lasso into cross_val_score\n",
    "    3). using a tuple, append the average of all results from step 2 into a list, along with the value of alpha`\n",
    "    \n",
    "When you're finished, you should have a list that has 9 tuples inside it, each one with the average cross validation score as well as the value of alpha associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** In Scikit-Learn cross validation is sometimes built into algorithms automatically.  Luckily this is the case with `Ridge` and `Lasso`.  If you're inclined to take a look at the `RidgeCV` and `LassoCV` methods, you can basically combine what we just did into one step.\n",
    "\n",
    "**RidgeCV:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html\n",
    "**LassoCV:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Building A Pipeline\n",
    "\n",
    "Let's try building some pipelines to test out different versions of our models more easily.  \n",
    "\n",
    "For this one, we are going to start fresh a little bit to get the hang of using our pipelines.  \n",
    "\n",
    "So......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following pipeline:\n",
    "\n",
    "We'll skip ordinal encoding for now.\n",
    "\n",
    " - one of either Ridge or Lasso, StandardScaler, and the CategoryEncoders categorical encoder\n",
    " - make sure to use the `cols` argument with the categorical encoder to include numeric variables that are actually categories if this is necessary\n",
    " - use the best value of alpha from the previous step for either one\n",
    " - fit your model on the entire training set (because we're using the cross-validated best version of alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
