{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab:  Random Forests & Regularized Linear Models -- Solutions\n",
    "\n",
    "Welcome!  Today's lab is going to allow us to blend together a number of techniques that have been brewing throughout unit 3:\n",
    "\n",
    " - Cross validating the parameters of different models\n",
    " - Regularized Linear Models (Ridge & Lasso)\n",
    " - And our newly added technique:  the Random Forest!  \n",
    " \n",
    "We'll continue working on the Ames dataset, and see if we can implement the different methods we've discussed so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1a:  Load in the training and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('../data/iowa_housing/train.csv')\n",
    "test  = pd.read_csv('../data/iowa_housing/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1b: Create the `y` variable for `SalePrice`, remove it from the training set, and drop the indexes for both datasets.  Take the log of `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "y = np.log(train['SalePrice'])\n",
    "train.drop('SalePrice', axis=1, inplace=True)\n",
    "test_id = test['Id']\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Fill in the missing values, using the techniques discussed so far\n",
    "\n",
    "**Note:** Like last time, you can copy & paste the answers from the solutions manual if the class is running out of time and/or you feel like you already understand the main points behind this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "train_empty = train.loc[:, train.isnull().sum() > 0]\n",
    "# grab the columns\n",
    "cols = train_empty.columns.tolist()\n",
    "# fill with the appropriate value  -- NA, Other, could also work\n",
    "train[['GarageType', 'GarageFinish']] = train[['GarageType', 'GarageFinish']].fillna('None')\n",
    "test[['GarageType', 'GarageFinish']]  = test[['GarageType', 'GarageFinish']].fillna('None')\n",
    "\n",
    "# we'll use this for GarageYrBlt since it's a numeric column\n",
    "train['GarageYrBlt'].fillna(0, inplace=True)\n",
    "test['GarageYrBlt'].fillna(0, inplace=True)\n",
    "\n",
    "# finding the values to use in the training set\n",
    "ms_mode   = train['MSZoning'].mode()[0]\n",
    "gcarsmean = train['GarageCars'].mean()\n",
    "\n",
    "# and applying them to the test set\n",
    "test['MSZoning'].fillna(ms_mode, inplace=True)\n",
    "test['GarageCars'].fillna(gcarsmean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Make Pipelines For Both a Random Forest and One of Ridge/Lasso\n",
    "\n",
    "Use the following steps for each one:\n",
    "\n",
    " - **Linear Models:**\n",
    "  - StandardScaler\n",
    "  - OrdinalEncoder (make sure to specify what columns you want this to apply to)\n",
    "  - OneHotEncoder\n",
    "  - Ridge/Lasso\n",
    "  \n",
    " - **Random Forests:**\n",
    "  - OrdinalEncoder\n",
    "  - OneHotEncoder\n",
    "  - RandomForest\n",
    "  \n",
    "**Note:** Do you understand why we're using different steps for each one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from category_encoders import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# mapping for the ordinal columns\n",
    "garage_mapping = {\n",
    "    'None': 0, # no garage\n",
    "    'Unf' : 1, # unfinished garage\n",
    "    'RFn' : 2, # partially finished garage\n",
    "    'Fin' : 3  # finished garage\n",
    "}\n",
    "\n",
    "col_mapping = {\n",
    "    'col': 'GarageFinish',\n",
    "    'mapping': garage_mapping\n",
    "}\n",
    "\n",
    "# Pipeline components\n",
    "sc    = StandardScaler()\n",
    "ore   = OrdinalEncoder(cols=['GarageFinish'], mapping=[col_mapping])\n",
    "ohe   = OneHotEncoder()\n",
    "ridge = Ridge()\n",
    "rf    = RandomForestRegressor()\n",
    "\n",
    "lm_pipe = make_pipeline(ore, ohe, sc, ridge)\n",
    "rf_pipe = make_pipeline(ore, ohe, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4a: Cross Validate The Best Version of Alpha for Your Linear Model\n",
    "\n",
    "This will follow a process very similar to the previous class.\n",
    "\n",
    " - create your list of alphas using `np.logspace`\n",
    " - using a for-loop, do the following:\n",
    "  - set the value of alpha for your model to the current one\n",
    "  - use cross validation to arrive at the validation score\n",
    "  - log the value of the validation score & alpha to a list\n",
    "  \n",
    " When you're done you should have a list that looks something like this:\n",
    " \n",
    "  `[(0.86747374, .001), (0.8547574, 0.1), (0.8573584, 1)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "alphas       = np.logspace(-3, 3, 7)\n",
    "ridge_scores = []\n",
    "\n",
    "# for loop to cross validate alpha\n",
    "for alpha in alphas:\n",
    "    lm_pipe.steps[3][1].set_params(alpha=alpha)\n",
    "    scores = cross_val_score(estimator=lm_pipe, X=train, y=y, cv=10)\n",
    "    ridge_scores.append((np.mean(scores), alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8616642766670427, 100.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and 100 wins\n",
    "max(ridge_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4b: Set the value of alpha to the one that gave you the best cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "lm_pipe.steps[3][1].set_params(alpha=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5a: Cross Validate The Ideal Value for `max_features` For Your Random Forest\n",
    "\n",
    "This will follow a process very similar to the previous step.\n",
    "\n",
    " - create a list of values that ranges from 0.2 - 0.9\n",
    " - using a for-loop, do the following:\n",
    "  - set the value of `max_features` for your model to the current one\n",
    "  - use cross validation to arrive at the validation score\n",
    "  - log the value of the validation score & max samples to a list\n",
    "  \n",
    " When you're done you should have a list that looks something like this:\n",
    " \n",
    "  `[(0.86747374, .2), (0.8547574, 0.3), (0.8573584, 0.4)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "sample_size = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "rf_scores   = []\n",
    "\n",
    "# do the cross validation\n",
    "for size in sample_size:\n",
    "    rf_pipe.steps[2][1].set_params(max_features=size)\n",
    "    scores = cross_val_score(estimator=rf_pipe, X=train, y=y, cv=10)\n",
    "    rf_scores.append((np.mean(scores), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8700499374632763, 0.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best values\n",
    "max(rf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5b: Set the value of `max_samples` in your pipeline to the best one found in your cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "rf_pipe.steps[2][1].set_params(max_features=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Fit your cross validated pipelines on your **entire** training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['GarageFinish'], drop_invariant=False,\n",
       "                                handle_missing='value', handle_unknown='value',\n",
       "                                mapping=[{'col': 'GarageFinish',\n",
       "                                          'mapping': {'Fin': 3, 'None': 0,\n",
       "                                                      'RFn': 2, 'Unf': 1}}],\n",
       "                                return_df=True, verbose=0)),\n",
       "                ('onehotencoder',\n",
       "                 OneHotEncoder(cols=['MSZoning', 'Neighborhood', 'GarageType'],\n",
       "                               drop_invariant=Fal...\n",
       "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                       criterion='mse', max_depth=None,\n",
       "                                       max_features=0.5, max_leaf_nodes=None,\n",
       "                                       max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=None,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "lm_pipe.fit(train, y)\n",
    "rf_pipe.fit(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Make predictions on your test set using each of your pipelines.\n",
    "\n",
    "**Note:** If you want the predictions to be in their original units, use the `np.exp()` method to transform your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "lm_preds = np.exp(lm_pipe.predict(test))\n",
    "rf_preds = np.exp(rf_pipe.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Put your predictions into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "rf_submission = pd.DataFrame({\n",
    "    'Id': np.arange(1461, 2920),\n",
    "    'SalePrice': rf_preds\n",
    "})\n",
    "\n",
    "lm_submission = pd.DataFrame({\n",
    "    'Id': np.arange(1461, 2920),\n",
    "    'SalePrice': lm_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this would create a submission file\n",
    "rf_submission.to_csv('rf_submission.csv', index=False)\n",
    "lm_submission.to_csv('lm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
