{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression & Scikit-Learn Intro\n",
    "\n",
    "This lab is designed to give everyone their first introduction to the Scikit-Learn API, and Linear Regression, one of the most commonly used techniques in predictive modeling.\n",
    "\n",
    "During this lab you'll see if you can build a model, understand its working parts, and make improvements to your results!  \n",
    "\n",
    "The great thing about `Scikit Learn` is that its API is almost identical from one algorithm to another, so once you get the hang of how to use it, using different methods is fairly seamless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Load in the `housing.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** What columns to include?  This is a bit of a topic unto itself, but for now let's keep it fairly simple, and choose the 5 columns that have the highest correlation (in magnitude) to the `PRICE` column. \n",
    "\n",
    "**hint:** `df.corr()`, and/or `sns.heatmap()` are helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Declare your `X` & `y` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Import `LinearRegression` and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Call the `fit()` method on `X` & `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Look at the values for `lreg.coef_` & `lreg.intercept_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Turn your model output into a more readable format.  \n",
    "\n",
    "Try using the following:\n",
    "\n",
    "  `coeff_dict = {'Column': X.columns, 'Weight': lreg.coef_}`\n",
    "  \n",
    "  `coeff = pd.DataFrame(coeff_dict)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8:** Using the table you created in the previous step, what column had the largest coefficient (in magnitude)?\n",
    "\n",
    "Does this mean it has the most predictive value of any column in your dataset? (We'll discuss this in class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9:** What is your model's score? (We haven't really talked about what this means yet.  Don't worry, we'll get to that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10:** What is the equation of your model?\n",
    "\n",
    "Ie, `y = coefval1 * RM + coefval2 * TAX + coefval3 * SomeColumnName + intercept`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11:** Make a column in your dataframe called `PREDICTION`, and make it the predicted values of each row in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 12:** Looking at your first observation, can you make sense of the predicted value?  Ie, how it was generated from your coefficients & intercept?  If you're the type to do this, see if you can recreate the prediction using just your samples, coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "\n",
    "If you've made it this far, good job.  You can congratulate yourself for having duly completed the meat of today's lesson.  However, there are more details to discuss with these things, and these questions will give you a head's up on future points of attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus 1:** Data Scaling\n",
    "\n",
    "The literal meaning of a coefficient is it's the expected change in `y` you would get by increasing its associated column's value by exactly 1.  \n",
    "\n",
    "What's problematic about this definition is that most of the time data exists on different scales, making the meaning of your coefficients less clear.  \n",
    "\n",
    "For example, the `TAX` column has a range of 200-800, and the `NOX` column has a range of 0.3-0.8.  Increasing the values in these columns by 1 will necessarily mean very different things since their scales are so different.  \n",
    "To get around this, you typically scale your data before feeding it to a Linear Regression model (or anything else that uses coefficients). \n",
    "\n",
    "You accomplish this by taking every column and subtracting its mean from every value, and then dividing each value in a column by its standard deviation.  \n",
    "\n",
    "You can do it like this:\n",
    "\n",
    "`X = X - X.mean()`\n",
    "\n",
    "`X = X / X.std()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a). Standardize Your Data, And Use the `Describe()` method to verify your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b). Refit your model on `X` and `y`, and look at your new coefficients.  Are they they the same or different?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c).  Look at your score.  Is it different?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d). What about your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus II: Basis Expansion**\n",
    "\n",
    "The most common problem with Linear Regression models is that data is not always so linear.  Sometimes there are increasing returns to scale, diminishing returns, outliers, or erratic jump points that make your results untrustworthy.  \n",
    "\n",
    "One common way to get around this is something called **basis expansion**, which is simply finding ways to capture irregular patterns in your data via different types of numeric transformations.  \n",
    "\n",
    "In fact, lots of cutting edge techniques can be accurately framed as basis expansions on linear models.  \n",
    "\n",
    "In this section, we'll see if we can find some low-hanging fruit in the columns that we currently have to perhaps better handle not-so-linear patterns. \n",
    "\n",
    "Here are some things you can try:\n",
    "\n",
    " - If the relationship between two columns looks like it's exponentially increasing or parabolic (bowl shaped), you can try raising the number to a higher power.  Ie, `df[col]**2 or df[col]**3`, etc.\n",
    " - If it looks like you are hitting diminishing returns you can try taking the square-root of a column and adding that to your mix of predictors\n",
    " - If a column looks like it's plagued by irregular values then you can use a log transformation `(np.log(df[col]))` to make it more numerically stable\n",
    " - If you think two columns (or more) had a multiplicative effect then you can try creating a new column that's the product of those columns multiplied together and use that in your regression.  These are called *interaction effects*.  Ie, do things like `CRIM` and `LSTAT` (socioeconomic status) reinforce one another?  If so, multiplying them together can capture their joint impact.\n",
    " \n",
    "You could potentially do any of these to any columns in `X` or `y`.\n",
    "\n",
    "With that said, try using either the `pairplot` or `regplot`, or some other data visualization tool to see if there's perhaps a higher order relationship to be captured.  If you see something that looks intriguing, add a new column to `X` that captures this relationship, re-run your regression, and see if your model score improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus III: Regularized Regression**\n",
    "\n",
    "Many times you'll have a dataset that has many columns that are highly correlated, or just of dubious quality and you're better off excluding them from your model.  \n",
    "\n",
    "In these circumstances, it can be difficult to get reliable results that replicate well to out-of-sample data, or reason about what to even include for your model.\n",
    "\n",
    "Two common variants of common Linear Regression which help with these issues are **Ridge Regression** and **Lasso Regression**.  \n",
    "\n",
    "They serve the same general purpose of reducing the impact of multicollinearity (highly correlated columns) and/or removal of low quality columns.  However, how they go about doing so is slightly different.\n",
    "\n",
    "For now, let's just see how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the following cell to import Ridge and Lasso Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the models here\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize instances of both, and fit them on your data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at the values of your coefficients.  How are they different from regular Linear Regression?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the parameters of each one, you'll notice they have something called `alpha`.  This is a value that can go as low as 0 and has no upper limit.  \n",
    "\n",
    "**Try changing the values of alpha for both Ridge and Lasso by multiples of 10, and notice what impact it has on your coefficients. (You can try values that are less than 1.  This is especially useful for Lasso, which is more sensitive to alpha than Ridge).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
