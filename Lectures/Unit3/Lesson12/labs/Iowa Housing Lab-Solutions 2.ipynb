{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iowa Housing Lab -- Solutions\n",
    "\n",
    "Welcome!! This lab is going to be a bit more of an advanced version of yesterday's class, where we build a regression model to predict housing prices, but this time do so with a dataset that has a more interesting mix of data -- ordinal and nominal features, as well as some missing values.\n",
    "\n",
    "**Important:** A summary of each of the columns in this dataset, and what their values mean, can be found here: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1).  Load in both your training & test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('../data/iowa_housing/train.csv')\n",
    "test  = pd.read_csv('../data/iowa_housing/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 19 columns):\n",
      "Id              1460 non-null int64\n",
      "MSSubClass      1460 non-null int64\n",
      "MSZoning        1460 non-null object\n",
      "LotArea         1460 non-null int64\n",
      "Neighborhood    1460 non-null object\n",
      "OverallQual     1460 non-null int64\n",
      "OverallCond     1460 non-null int64\n",
      "YearBuilt       1460 non-null int64\n",
      "GrLivArea       1460 non-null int64\n",
      "1stFlrSF        1460 non-null int64\n",
      "2ndFlrSF        1460 non-null int64\n",
      "GrLivArea.1     1460 non-null int64\n",
      "FullBath        1460 non-null int64\n",
      "HalfBath        1460 non-null int64\n",
      "GarageType      1379 non-null object\n",
      "GarageYrBlt     1379 non-null float64\n",
      "GarageFinish    1379 non-null object\n",
      "GarageCars      1460 non-null int64\n",
      "SalePrice       1460 non-null int64\n",
      "dtypes: float64(1), int64(14), object(4)\n",
      "memory usage: 216.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also....when you're cleaning training & test sets, it's usually a good idea to separate the column you're trying to predict from everything else.  \n",
    "\n",
    "For now, declare `y` to be the `SalePrice` column, and then remove it from the training set entirely.  You can drop the `ID` column too, since it encodes nothing meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "y = train['SalePrice']\n",
    "train.drop('SalePrice', axis=1, inplace=True)\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2).  There are missing values throughout this dataset.  For the time being, let's try and do a few things:**\n",
    "\n",
    " - were these missing values likely to be randomly occurring, or are they likely encoding for something else?  \n",
    " \n",
    "If values are encoding for something else, there are usually either high correlations with missing values in similar columns, and/or they could potentially represent a particular rank in a hierarchy -- ie, 'None', 0, 'Other', etc.  Ie, the missing values basically are encoding for something specific, it's just not mentioned.\n",
    "\n",
    "Take a look at the column descriptions, see what you think they might be.\n",
    "\n",
    " - if you think they are missing at random, fill in the missing values with their mean(numeric columns) or mode(categorical columns)\n",
    " - if you think they are **not** missing at random, then go ahead and fill them in with a value to encode what they are (0, 'Other', and 'None' are common choices)\n",
    " \n",
    "**Hint:** You can try encoding null & non-null values to 0 and 1, respectively, and use the corr() method on that. \n",
    " \n",
    "*If filling in missing values, make sure to perform this operation on the training and test set, using values from the training set for imputation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "train_empty = train.loc[:, train.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GarageType  GarageYrBlt  GarageFinish\n",
       "GarageType           1.0          1.0           1.0\n",
       "GarageYrBlt          1.0          1.0           1.0\n",
       "GarageFinish         1.0          1.0           1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is a 100% correlation between the empty values in these columns\n",
    "# they all encode for a garage -- these almost certainly represent the same thing\n",
    "train_empty.isnull().astype(int).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the columns\n",
    "cols = train_empty.columns.tolist()\n",
    "# fill with the appropriate value  -- NA, Other, could also work\n",
    "train[['GarageType', 'GarageFinish']] = train[['GarageType', 'GarageFinish']].fillna('None')\n",
    "test[['GarageType', 'GarageFinish']]  = test[['GarageType', 'GarageFinish']].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this for GarageYrBlt since it's a numeric column\n",
    "train['GarageYrBlt'].fillna(0, inplace=True)\n",
    "test['GarageYrBlt'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass      0\n",
       "MSZoning        4\n",
       "LotArea         0\n",
       "Neighborhood    0\n",
       "OverallQual     0\n",
       "OverallCond     0\n",
       "YearBuilt       0\n",
       "GrLivArea       0\n",
       "1stFlrSF        0\n",
       "2ndFlrSF        0\n",
       "GrLivArea.1     0\n",
       "FullBath        0\n",
       "HalfBath        0\n",
       "GarageType      0\n",
       "GarageYrBlt     0\n",
       "GarageFinish    0\n",
       "GarageCars      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are still some empty columns in the test set, we'll impute these \n",
    "# using values from the training set\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the values to use in the training set\n",
    "ms_mode   = train['MSZoning'].mode()[0]\n",
    "gcarsmean = train['GarageCars'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and applying them to the test set\n",
    "test['MSZoning'].fillna(ms_mode, inplace=True)\n",
    "test['GarageCars'].fillna(gcarsmean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3): Ordinal vs Categorical Columns**\n",
    "\n",
    "There are a number of categorical columns in this dataset, and they could represent both ordinal or nominal data.  \n",
    "\n",
    "Take a look at their descriptions, and decide which one belongs to which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here (no real code required for this one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4):  Go Ahead and Change Your Ordinal Variables To Their Appropriate Values, If They Exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# we'll assume the GarageFinish is ordinal.  Ie, FinishedGarage > Unfinished Garage\n",
    "garage_mapping = {\n",
    "    'None': 0, # no garage\n",
    "    'Unf' : 1, # unfinished garage\n",
    "    'RFn' : 2, # partially finished garage\n",
    "    'Fin' : 3  # finished garage\n",
    "}\n",
    "\n",
    "train['GarageFinish'] = train['GarageFinish'].map(garage_mapping)\n",
    "test['GarageFinish']  = test['GarageFinish'].map(garage_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5):  Now, OneHot Encode Your Dataset For Your Remaining Categorical Columns** \n",
    "\n",
    "**Note:** You want your training and your test sets attached for this one.  Detach them when you're finished.\n",
    "\n",
    "**2nd Note:** Some columns are categorical, even if they're encoded as numbers.  the `MSSubClass` is essentially a zoning category, even though it's encoded as a number.  It's a good idea to encode these variables as strings using the `astype` method.\n",
    "\n",
    "**3rd Note:** We'll discuss better ways to get around this, but the test set has a value in the `MSSubClass` column that is **not** in the training set.  For the time being just drop the column `MSSubClass_150` from both training and test sets before proceeding to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSSubClass is really a category, moreso than a true number\n",
    "# so we'll add it to the list of items to be encoded\n",
    "train['MSSubClass'] = train['MSSubClass'].astype(str)\n",
    "test['MSSubClass']  = test['MSSubClass'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate and encode\n",
    "master = pd.concat([train, test])\n",
    "master = pd.get_dummies(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop MSSubClass150\n",
    "master.drop('MSSubClass_150', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and split back apart\n",
    "train  = master.iloc[:1460].copy()\n",
    "test   = master.iloc[1460:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6): Standardize Your Data On Your Training and Test Sets**\n",
    "\n",
    "**Remember:** Use the values from your training set to standardize your test set!  \n",
    "\n",
    "Ask me if you have any questions on how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = train.mean()\n",
    "train_stds  = train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the training set\n",
    "train_std = train - train_means\n",
    "train_std /= train_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and do the same for the test set\n",
    "test -= train_means\n",
    "test /= train_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7):  Create a validation set out of your training set, and import Linear Regression**\n",
    "\n",
    "Since there is no time based component, random shuffling is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8): Initialize Linear Regression, fit it on your training set, and score it on your validation set to get a feel for how you did.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853339945174324"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "lreg.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9):  Finally, go ahead and make your predictions on your test set.**\n",
    "\n",
    "Create a dataframe with the following the following columns: \n",
    "\n",
    "    `ID`: The original ID of each row in the test set.  Goes from 1461 - 2919\n",
    "    `SalePrice`: The predicted Sale Price of the house in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "preds = pd.DataFrame()\n",
    "preds['ID'] = np.arange(1461, 1461+1459)\n",
    "preds['prediction'] = lreg.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the `to_csv()` method to output the file to a csv.  Make sure to use `index=False` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** Can you improve your score?\n",
    "\n",
    "The first part of this lab was meant to be a walk through of the basics of prepping a data set and getting it ready.\n",
    "\n",
    "However, there's a lot that could be improved upon!  \n",
    "\n",
    "Using validation scores as your guide, you could try and look at some of the following:\n",
    "\n",
    " - Removing outliers from the target variable, or using log transformations to make the data smoother\n",
    " - There are lots of highly correlated variables in this dataset.  Do the 4 different columns about the fireplace really tell you something that different from one another?  You can try averaging multiple columns into one if they're highly correlated, or removing some entirely to see if it improves anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
