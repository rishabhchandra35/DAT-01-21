{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Bonus Challenge\n",
    "\n",
    "This notebook provides (optional) questions for you to explore Linear Regression models, and how they're implemented in the python ecosystem. \n",
    "\n",
    "The notebook consists of four different parts:\n",
    "\n",
    " - **Model Interpretation:** How to better understand the impact of your coefficient values on your target variable.\n",
    " - **Statistical testing with Statsmodels:** Use a companion library to better interpret regression results\n",
    " - **Extending SKlearn:** Using the `preprocessing` module to make model building more efficient\n",
    " - **Regression Concept Deep Dive:** Looking at some of the fundamental equations of regression models to better understand how they operate.\n",
    " \n",
    "You can answer these questions in any order, as best suits your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation\n",
    "\n",
    "This section asks different questions about interpreting the coefficients of regression models.  \n",
    "\n",
    "To answer them, fit an instance of `LinearRegression` on the `housing.csv` dataset using `PRICE` as the target variable and every other column as part of `X`.  Make sure your data is standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1).** Standardizing your data changes your coefficients, but not your final results.  Can you explain this effect graphically?  (**Hint:** Histograms help a lot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2).** With standardized data, each column has an average value of 0 and a standard deviation of 1.  This means if the value of a column is its average, it will have no additional effect on the price of a house, and the observed coefficient value comes from increasing/decreasing the column value 1 standard deviation from where it's at.  \n",
    "\n",
    "With that being said......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the impact of adding one additional room to a house's selling price?**  (**Note:**  This is NOT asking what happens if you increase the number of rooms by one standard deviation.  Just ONE room)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3).** If a house has 3 rooms in it, what would be the expected change in the house's selling price as a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Deep Dive With Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main libraries for statistical methods in Python.  `SKLearn` and `Statsmodels`.  They are similar in their ambitions, but slightly different in their scope.  `SKlearn` is built around the idea of using a dataset to make predictions, whereas `Statsmodels` is built on the idea of producing test statistics to provide insight into your results.  \n",
    "\n",
    "We'll spend most of the class using `SKLearn`, but `Statsmodels` provides useful information about a model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next code block will discuss its basic syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.555091</td>\n",
       "      <td>1.929839</td>\n",
       "      <td>2.761836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.529927</td>\n",
       "      <td>1.438684</td>\n",
       "      <td>4.254864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.487247</td>\n",
       "      <td>1.051665</td>\n",
       "      <td>7.531154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.142323</td>\n",
       "      <td>2.664511</td>\n",
       "      <td>6.983797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.636811</td>\n",
       "      <td>2.001381</td>\n",
       "      <td>7.029455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C\n",
       "0 -0.555091  1.929839  2.761836\n",
       "1  1.529927  1.438684  4.254864\n",
       "2 -0.487247  1.051665  7.531154\n",
       "3  3.142323  2.664511  6.983797\n",
       "4  0.636811  2.001381  7.029455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are randomly generating fake data, to use in a dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fake_data = {\n",
    "    'A': np.random.normal(1, 3, size=100),\n",
    "    'B': np.random.normal(2, 1, size=100),\n",
    "    'C': np.random.normal(6, 2, size=100)\n",
    "}\n",
    "\n",
    "# turn it into a dataframe\n",
    "data = pd.DataFrame(fake_data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting a Regression Model With Statsmodels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      C   R-squared:                       0.026\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     1.269\n",
      "Date:                Thu, 21 Nov 2019   Prob (F-statistic):              0.286\n",
      "Time:                        11:55:33   Log-Likelihood:                -202.01\n",
      "No. Observations:                 100   AIC:                             410.0\n",
      "Df Residuals:                      97   BIC:                             417.8\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          6.1515      0.185     33.213      0.000       5.784       6.519\n",
      "A              0.0239      0.187      0.128      0.899      -0.348       0.396\n",
      "B             -0.2983      0.187     -1.593      0.115      -0.670       0.073\n",
      "==============================================================================\n",
      "Omnibus:                        0.092   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.955   Jarque-Bera (JB):                0.258\n",
      "Skew:                          -0.034   Prob(JB):                        0.879\n",
      "Kurtosis:                       2.760   Cond. No.                         1.12\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "# declare X and y\n",
    "X = data[['A', 'B']]\n",
    "y = data['C']\n",
    "\n",
    "X_std = (X - X.mean()) / X.std()\n",
    "\n",
    "# this step might look a little weird, but bare with me for now\n",
    "X_std = add_constant(X_std)\n",
    "\n",
    "# this is the equivalent of doing lreg = LinearRegression() that we did previously\n",
    "# notice that you put y before X\n",
    "mod = sm.OLS(y, X_std)\n",
    "\n",
    "# because we loaded in y and X previously, no need to use them here\n",
    "results = mod.fit()\n",
    "\n",
    "# the results() object provides a lot of data, most importantly the summary(), which we can see here\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results might seem a bit overwhelming at first, but let's take a step back and evaluate what we're looking at.\n",
    "\n",
    "First, the results:\n",
    "\n",
    " - Not surprisingly, our r-squared value is hovering right around 0, which should be expected given that we're dealing with random data\n",
    " - In a similar vein, we should expect the coefficients for A and B are also right around 0, indicating they have no discernible impact on the value of C.\n",
    " \n",
    "Next, let's take a look at the middle section of the summary which lists the values for `coef`, `std err`, `t`, `P>|t|`, and `[0.025  0.975]`.\n",
    "\n",
    "What's important here is that when a linear model derives a coefficient, it's not meant to be a static value, but rather the **average value for an observed distribution**. \n",
    "\n",
    "Or to rephrase the issue, when we see that the coefficient value of A is 0.0239, this means that if we were to re-run a similar experiment many times, 0.0239 is the value we would expect to observe most frequently, and we should expect that value of the coefficient of A to have a standard error (very similar to the standard deviation) of 0.187.\n",
    "\n",
    "With the information from above, we can easily derive **confidence intervals** for our coefficients, which you can see above in the column denoted `[0.025  0.975]`.\n",
    "\n",
    "Basically, this number means, 95% of the time we should expect the value of this coefficient to be between these two values.\n",
    "\n",
    "Two points:\n",
    "\n",
    " - This is a useful metric to figure out high and low estimations for a particular column's impact\n",
    " - Coefficients that have a 95% confidence interval that passes over 0 are good candidates to be removed from your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4).**  Use `statsmodels` to run a regression model on your dataset, and observe your results.  Then, find out.....**what variables are good candidates to be removed from your dataset?**\n",
    "\n",
    "Don't forget to use the `add_constant` method to get valid results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5).** Re-run your regression model without the `add_constant` function, and observe the changes in your results.  Any idea what it's doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Scikit Learn\n",
    "\n",
    "An under appreciated benefit of `SKlearn` is that it comes with a number of additional modules that make it easier to process and build models, regardless of what technique you are using.  \n",
    "\n",
    "One such module is the `preprocessing` module, which we'll take a look at here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `preprocessing` module contains a number of built-in functions for shaping data, before feeding them into a model.  You can see more detail about it here:  https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "They allow you to import different modules that allow you to shape your data in particular ways.  For example, the `StandardScaler` module allows you to center your data in a way we described in class. \n",
    "\n",
    "**The Transformer API**\n",
    "\n",
    "The API in `SKLearn` basically follows two different patterns:  \n",
    "\n",
    " - one for algorithms that you fit your data on\n",
    " - one for modules that transform your data into something else\n",
    " \n",
    " If you're using an algorithm, your best friends are `fit()`, `predict()`, and `score()`.  However, if you're using a transformer, your main function calls happen in three different ways:\n",
    " \n",
    " - `fit()`: find the appropriate values for your columns and store them\n",
    " - `fit_transform()`:  do the same as `fit()`, but also change the data that you call it on\n",
    " - `transform()`: reshape a dataset based on the stored values from the `fit()` method\n",
    " \n",
    "Let's take a look to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# initialize it, just like you would an algorithm\n",
    "sc = StandardScaler()\n",
    "\n",
    "# if you want to transform a dataset, and store its values, you use the fit_transform() method\n",
    "scaled_data = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytime you invoke the `fit()` method using a module that has the transformer API, you can then access the stored values of the data you transformed for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.23698437, 2.1173855 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the average values of the columns\n",
    "sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.94517892, 1.13854336])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their variances\n",
    "sc.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you want, you can call the `transform()` method on *new* data, and transform it according to the stored values from your old data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll make another fake dataframe\n",
    "\n",
    "other_data = {\n",
    "    'A': np.random.normal(1, 3, size=100),\n",
    "    'B': np.random.normal(2, 1, size=100),\n",
    "    'C': np.random.normal()\n",
    "}\n",
    "\n",
    "other_data = pd.DataFrame(other_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then standardize it using the scaler\n",
    "# notice how we're using just the transform() method\n",
    "other_data = sc.transform(other_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you look at the original data that we scaled, its average values are a clean 0, and its variances a clean 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.88178420e-18 -1.64313008e-16] [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_data.mean(0), scaled_data.var(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the data that was later transformed has values that are just a little bit different, because its using the means and variances of the data it was originally fit on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27987504 -0.01137965] [1.35632956 0.75008325]\n"
     ]
    }
   ],
   "source": [
    "print(other_data.mean(0), other_data.var(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful when dealing with training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6a):** Create a training and test set from the housing data.  Use the `StandardScaler` to transform your training data, and then do the same on the test set, using the stored values from the `fit_transform()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression:  Concept Deep Dive\n",
    "\n",
    "**Warning:**  This section is going beyond what might be considered practical use of what's covered in class.  If you are happy just to be able to use different API calls in one library or another to get results, then you can skip this next section.\n",
    "\n",
    "However, I find lots of people are secretly 'Math curious', and enjoy a feeling of empowerment by being able to decipher certain types of formal concepts that they may have previously perceived to be inscrutable.  \n",
    "\n",
    "Transforming the mysterious to the mundane is a kind of magical process.  It also makes the latest technology du jour boring in a good way, because you (correctly) perceive them to be just temporary ways of being able to employ different concepts that are much more permanent.  Libraries come and go on a five-year cycle, but the ideas they manipulate are practically immortal.\n",
    "\n",
    "So if you would like to arrive at a deeper, more nuanced understanding of what's driving our results, then feel free to complete the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Regression:  Concept Deep Dive\n",
    "\n",
    "In previous classes, we took a closer look at some basic statistical definitions which reuse themselves over and over.\n",
    "\n",
    "In particular:\n",
    "\n",
    "1. **Standard Deviation:** A scaled measure of dispersion around the center of a normal distribution.\n",
    "2. **Variance:**  A non-scaled measure of dispersion that measures the **total amount** of dispersion a particular column has around its average.  \n",
    "3. **Covariance:** A metric that tracks the total amount of variability between two columns\n",
    "4. **Correlation:** A metric that scales the covariance between variables to a value that's between -1 and 1, by dividing it by the standard deviations of deach column.\n",
    "\n",
    "**Univariate Linear Regression**\n",
    "\n",
    "We can take these basic definitions and use them relatively easily to arrive at the parameters for a linear regression model with one predictor.  \n",
    "\n",
    "The equation for univariate linear regression is the following:\n",
    "\n",
    " $$ y = \\beta_{1}x + \\beta_{0} $$\n",
    " \n",
    " Here, $ \\beta_{1} $ is the coefficient for $ x $, and $ \\beta_{0} $ is the intercept.  \n",
    " \n",
    " Ie, this is a greek letter version of the formula $ y = mx + b $\n",
    " \n",
    " When solving for this, you want to find out the slope of the line for $x$ and its intercept.  These numbers are fairly easily derived from the definitions given above.  \n",
    " \n",
    "The formula for finding the coefficient of $x$ is the following:\n",
    "\n",
    "$$ \\beta_{1} =  \\frac{\\frac{1}{n - 1}\\sum{(x_{i} - \\bar{x})(y_{i} - \\bar{y})}}{\\frac{1}{n-1}\\sum{(x_{i} - \\bar{x})^2}}  $$\n",
    "\n",
    "This expression might look daunting, but if you're getting some mental indigestion, just take a step back, relax, and remind yourself of what we've already learned.  It's a simple recombination of what's been covered so far in class.\n",
    "\n",
    "Look at the numerator in the above expression.  Do you recognize what it is?  \n",
    "\n",
    "What about the denominator?  \n",
    "\n",
    "If it's not immediately clear what the formula for $ \\beta_{1} $ is asking of you, take a few minutes to see if you can figure it out.  \n",
    "\n",
    "We'll wait a few minutes before we go on to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay.....hopefully by now you've taken at least a few minutes to try and connect the dots.  But if you want to get straight to the point, here's what the above formula boils down to:\n",
    "\n",
    "$$ \\beta_{1} = \\frac{covar(x, y)}{var(x)} $$\n",
    "\n",
    "Ie, to get the slope of the line, you simply divide the covariance of x and y, by the variance of x.  That's it!\n",
    "\n",
    "In a similar vein, the formula for deriving the intercept is also relatively straight forwrad.  \n",
    "\n",
    "It's given by the following:  \n",
    "\n",
    "$$ \\beta_{0} = \\bar{y} - \\beta_{1}\\bar{x} $$\n",
    "\n",
    "ie, take the average value of y, and subtract the value of the slope multiplied by the average of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7).** Your turn.  See if you can derive the slope and intercept for a univariate regression model that uses the `RM` column for `X`, and the `PRICE` column for `y`.  You don't have to standardize your data for this one.  You should be able to use `SKlearn` to double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Regression:  Concept Deep Dive\n",
    "\n",
    "Deriving the coefficients for multivariate regression is a little more involved, but can ultimately be done in one step.  \n",
    "\n",
    "There are five or six different ways to get them working, but the most commonly identified way of doing so is given by the following expression:\n",
    "\n",
    "$$ \\beta = (X^TX)^{-1}X^Ty $$\n",
    "\n",
    "Where $ \\beta $ is the set of all coefficients.\n",
    "\n",
    "To get this expression working, there are a few additional details you should be aware of.  \n",
    "\n",
    " - The 'T' in the superscript is the transpose of a matrix, which inverts the columns and rows of a matrix\n",
    "  - In numpy this would be done simply by calling `X.T`\n",
    " - Multiplying matrices is not the same as multiplying regular numbers.  Ie, the expression $XX$ is not just $X$ * $X$. Rather it would be the following numpy expression:  `X.dot(X)`\n",
    " - The '-1' in the superscript is the *inverse* of $ X^TX $.  It's basically the matrix equivalent of dividing a number by one.   - In numpy, you do this by calling the method `np.linalg.inv()`\n",
    " \n",
    "If you can connect those dots, you should be able to arrive at the values of your coefficients by hand.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8a).**  See if you can crack the above expression to arrive at your coefficients.  Make sure you are using a standardized version of your data.\n",
    "\n",
    "**Hint:** Matrix operations are picky about dimensions.  You should expect to get several error messages saying 'the dimensions of such and such are not aligned' while trying to arrive at the correct answer.  Be prepared, and don't let it discourage you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8b).**  Do you see what $X^TX$ is? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
