{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_df(file_path, chunksize=1000):\n",
    "    #counter variables to store count of null values and average of each streamed chunk \n",
    "    null_sum = 0\n",
    "    avg_sum = []\n",
    "    #iterate through each chunk and append relevant info to counter variables\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        null_sum += chunk.isnull().sum()\n",
    "        dtypes = chunk.dtypes\n",
    "        avg_sum.append(chunk.mean())\n",
    "    \n",
    "    #calculate mean of all chunks, then convert it to a dictionary\n",
    "    avg_val = (pd.concat(avg_sum).groupby(level=0).mean()).to_dict()\n",
    "    \n",
    "    #convert null totals into a DataFrame and add a dtype column\n",
    "    df = pd.DataFrame(null_sum, columns=['null values'])\n",
    "    df['dtype'] = dtypes\n",
    "    \n",
    "    #convert dataframe to dictionary\n",
    "    df_dict = df.to_dict('index')\n",
    "    \n",
    "    #if dtype is float or integer, append average value \n",
    "    for k, v in df_dict.items():\n",
    "        if v['dtype'] == int or v['dtype'] == float:\n",
    "            v['avg_val'] = avg_val[k]\n",
    "\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df(file_path_read, file_path_write, chunksize=1000, missing_vals=None):\n",
    "    #create a boolean variable to determine if the chunk requires a header\n",
    "    first_chunk = True\n",
    "    #stream in the file using path and chunksize entered as arguments\n",
    "    for chunk in pd.read_csv(file_path_read, chunksize=chunksize):\n",
    "        #if missing_vals arguement is entered, iterate over each column of the chunk\n",
    "        if missing_vals != None:\n",
    "            for col_name in chunk:\n",
    "                #if column is int or float, fill missing values with average (from probe_df function)\n",
    "                if chunk[col_name].dtype == int or chunk[col_name].dtype == float:\n",
    "                    chunk[col_name] = chunk[col_name].fillna(missing_vals[col_name]['avg_val'])\n",
    "        \n",
    "        #if it's the first iteration, include the header when writing to path; else, header=False\n",
    "        if first_chunk:\n",
    "            chunk.to_csv(file_path_write, mode='w', header=True, index=False)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            chunk.to_csv(file_path_write, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRIP_ID': {'null values': 0,\n",
       "  'dtype': dtype('int64'),\n",
       "  'avg_val': 1.3886251201260434e+18},\n",
       " 'CALL_TYPE': {'null values': 0, 'dtype': dtype('O')},\n",
       " 'ORIGIN_CALL': {'null values': 1345900,\n",
       "  'dtype': dtype('float64'),\n",
       "  'avg_val': 24774.51827473647},\n",
       " 'ORIGIN_STAND': {'null values': 904091,\n",
       "  'dtype': dtype('float64'),\n",
       "  'avg_val': 30.38636597647096},\n",
       " 'TAXI_ID': {'null values': 0,\n",
       "  'dtype': dtype('int64'),\n",
       "  'avg_val': 20000348.535627205},\n",
       " 'TIMESTAMP': {'null values': 0,\n",
       "  'dtype': dtype('int64'),\n",
       "  'avg_val': 1388625119.5060449},\n",
       " 'DAY_TYPE': {'null values': 0, 'dtype': dtype('O')},\n",
       " 'MISSING_DATA': {'null values': 0, 'dtype': dtype('bool')}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'https://dat-data.s3.amazonaws.com/taxi.csv'\n",
    "column_info = probe_df(path, chunksize=500)\n",
    "column_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://dat-data.s3.amazonaws.com/taxi.csv'\n",
    "path_write = 'taxi_fillna.csv'\n",
    "write_df(path, path_write, chunksize=500, missing_vals=column_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRIP_ID': {'null values': 0,\n",
       "  'dtype': dtype('int64'),\n",
       "  'avg_val': 1.3886251201260434e+18},\n",
       " 'CALL_TYPE': {'null values': 0, 'dtype': dtype('O')},\n",
       " 'ORIGIN_CALL': {'null values': 0,\n",
       "  'dtype': dtype('float64'),\n",
       "  'avg_val': 24713.897460747816},\n",
       " 'ORIGIN_STAND': {'null values': 0,\n",
       "  'dtype': dtype('float64'),\n",
       "  'avg_val': 30.332316061858652},\n",
       " 'TAXI_ID': {'null values': 0,\n",
       "  'dtype': dtype('int64'),\n",
       "  'avg_val': 20000348.535627205},\n",
       " 'TIMESTAMP': {'null values': 0,\n",
       "  'dtype': dtype('int64'),\n",
       "  'avg_val': 1388625119.5060449},\n",
       " 'DAY_TYPE': {'null values': 0, 'dtype': dtype('O')},\n",
       " 'MISSING_DATA': {'null values': 0, 'dtype': dtype('bool')}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rerun to check null\n",
    "probe_df('taxi_fillna.csv', chunksize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
