{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Linear Regression and Train/Test Split\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We've discussed overfitting in the context of bias and variance, and we've touched on some techniques that are used to avoid overfitting (but haven't practiced them yet). In this project, we'll practice a fundamental method for avoiding overfitting that is commonly referred to as: _train/test split validation_. \n",
    "\n",
    "This is similar to something called \"cross-validation\" — in fact, it is a type of cross-validation — in that we will be splitting the data into two subsets:\n",
    "* A subset on which to train our model.\n",
    "* A subset on which to test our model's predictions.\n",
    "\n",
    "This serves two useful purposes:\n",
    "* We prevent overfitting by not using all of the data.\n",
    "* We have some remaining data we can use to evaluate our model.\n",
    "\n",
    "While this may seem like a relatively simple idea, **there are some caveats** to putting it into practice. For example, if you are not careful, it is easy to take a non-random split. Suppose we have salary data on technical professionals that is composed of 80 percent data from California, 20 percent data from elsewhere, and is sorted by state. If we split our data into 80 percent training data and 20 percent testing data, we might inadvertantly select all the California data to train and all the non-California data to test. In this case, we've still overfit on our data set because we did not sufficiently randomize the data.\n",
    "\n",
    "Note: In a situation like this, you could use a technique called _k-fold cross-validation_, which is cross-validation applied to more than two subsets. In particular, in k-fold cross-validation, you'd partition your data into $k$ subsets and train on $k-1$ one of them, holding the last slice for testing. You would do this for each of the possible $k-1$ subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Requirements\n",
    "\n",
    "The goal of this project will be to create a test-training split to compare multiple models on the same Boston housing data set. For example, you might choose to compare different linear models on the same data.\n",
    "\n",
    "In this project, you'll fit two to three different models on the Boston housing data. For example, you could pick two different subsets of variables, one or more polynomial models, or any other model you'd like. \n",
    "\n",
    "### Here's What We Will Be Doing:\n",
    "\n",
    "* Work with Boston housing data to predict the value of a home\n",
    "* Create a test-train split of the data.\n",
    "* Train your model on the training data.\n",
    "* Evaluate your model on the test data.\n",
    "* Repeat with other variables.\n",
    "* Rank the models by how well they score on the testing data set. \n",
    "* Don't forget to interpret your findings! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A k-fold cross-validation creates a hold portion of your data set for each iteration of training and validating:\n",
    "\n",
    "![](http://i.imgur.com/0PFrPXJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "As a real estate developer, you are being asked to model the median home price of various houses in the city of Boston using data from the US census. Your goal is to predict a continuous, numeric output (price) based on a combination of discrete features that you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X = pd.DataFrame(boston.data,\n",
    "                 columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target,\n",
    "                 columns=['MEDV'])\n",
    "y = np.log(y)\n",
    "#added this, will want the log of y always\n",
    "\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUIRED: Clean Up Data and Perform Exporatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Boston data is from scikit-learn, so it _ought_ to be pretty clean, but you should always perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory data analysis.\n",
    "\n",
    "# Include: total nulls, index, data types, shape, summary statistics, and the number of unique values for each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()\n",
    "#doesn't seem to be any null values in this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes\n",
    "#every column is a float which is what we want here.  If there were categorical columns, we'd want to one hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "#the data set only has 503 rows, pretty small so probably expect some variance when cutting into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       504\n",
       "ZN          26\n",
       "INDUS       76\n",
       "CHAS         2\n",
       "NOX         81\n",
       "RM         446\n",
       "AGE        356\n",
       "DIS        412\n",
       "RAD          9\n",
       "TAX         66\n",
       "PTRATIO     46\n",
       "B          357\n",
       "LSTAT      455\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `scikit-learn` Linear Regression\n",
    "\n",
    "### REQUIRED: Pick 3-4 predictors (i.e. CRIM, ZN, etc...) that you will use to predict your target variable, MEDV.\n",
    "Score and plot your predictions. What do these results tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a20d633d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('/Users/kinaabe/Kinadat/dat-1-21/Unit3/data/housing.csv')\n",
    "sns.heatmap(df.corr())\n",
    "# run heatmap to see which values are correlated to price.  i used a different data set to do this because it included\n",
    "#the Y variable in the housing.csv set.  This boston set splits the Y upfront.  By running this, I can choose the \n",
    "#variables I believe are highly correlated with PRICE.  Doing this instead of randomly picking columns.\n",
    "#LSTAT \n",
    "#PTRATIO\n",
    "#TAX\n",
    "#RAD\n",
    "#INDUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>TAX</th>\n",
       "      <th>RAD</th>\n",
       "      <th>INDUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.3</td>\n",
       "      <td>296.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.14</td>\n",
       "      <td>17.8</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.8</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSTAT  PTRATIO    TAX  RAD  INDUS\n",
       "0   4.98     15.3  296.0  1.0   2.31\n",
       "1   9.14     17.8  242.0  2.0   7.07\n",
       "2   4.03     17.8  242.0  2.0   7.07\n",
       "3   2.94     18.7  222.0  3.0   2.18\n",
       "4   5.33     18.7  222.0  3.0   2.18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[['LSTAT', 'PTRATIO', 'TAX','RAD', 'INDUS']]\n",
    "X.head()\n",
    "#cutting the dataframe here into the columns I care about.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# standardize the set.  Instead of manually doing this, we can use the StandardScaler.  \n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7101349095963227"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "lreg.fit(X, y)\n",
    "lreg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7101227315400359"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X,y)\n",
    "ridge.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X,y)\n",
    "lasso.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I try to see if there is improvement to the score if different alpha is used.  \n",
    "#I'm actually not sure why the scores are so low though, the alpha in line 15 should be =1 which means the score produced\n",
    "#there should be somewhat similar to the score in  (0.21571362643790443, 1.0)... Perhaps because the cv fold? changed\n",
    "#it from 10 to 5 and it looks better.  \n",
    "ridge_scores = []\n",
    "alphas = np.logspace(-3,3,7)\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge.set_params(alpha=alpha)\n",
    "    scores = cross_val_score(estimator = ridge,X=X,y=y,cv=5)\n",
    "    ridge_scores.append((np.mean(scores),alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5439850870004165, 0.001),\n",
       " (0.5439894132044467, 0.01),\n",
       " (0.5440320685139101, 0.1),\n",
       " (0.5444017936588985, 1.0),\n",
       " (0.5447809523436251, 10.0),\n",
       " (0.5070383101358387, 100.0),\n",
       " (0.13941823769122347, 1000.0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the results tell me that normal linear regression is the best model for this data set and columns I chose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUIRED: Try 70/30 and 90/10 train/test splits: 70% of the data for training - 30% for testing, then 90% for training - 10% for testing.\n",
    "Score and plot both of these approaches. How do your metrics change? What does this tell us about the size of training/testing splits? Include a written response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724125685291064"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "lreg.score(X_test, y_test)\n",
    "#we want to fit on the trainingset, score on the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6527569947559408"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train2, y_train2)\n",
    "lreg.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Yes the training to testing set differences change the results of the score.  We went from a score of 72% to 65% just by changing the training set from 30 to 10.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Try the k-fold cross-validation technique described above, varying the number of folds from 5 to 10\n",
    "What seems optimal? How do your scores change? What is the variance like? Try different folds to get a sense of how this impacts your score. What are the tradeoffs associated with choosing the number of folds? Include a written response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scores = []\n",
    "folds = [5,6,7,8,9,10]\n",
    "\n",
    "for fold in folds:\n",
    "    scores = cross_val_score(estimator=lreg, X=X_test, y=y_test, cv=fold)\n",
    "    k_scores.append((np.mean(scores),fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7038287655300131, 5),\n",
       " (0.6933154708839845, 6),\n",
       " (0.7041487335911546, 7),\n",
       " (0.6851726414638141, 8),\n",
       " (0.6854155262642033, 9),\n",
       " (0.6784691342926726, 10)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7041487335911546, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(k_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By cross validating the data, we find that there is a reduction in the realistic score of the data.  Before, we saw a score of 0.7835493319350365 on our test set but by slicing the data in different ways and scoring on different aspects of the data set, the more realistic score observed is .75.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS\n",
    "Practice the same workflow you just worked through above, but this time use Statsmodels instead of Sklearn for linear regression. See example formulas below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Statsmodels Formulas\n",
    "\n",
    "Adjust the formula using your chosen metrics from the housing data. Remember, your workflow here is the same, but the syntax is a little different. Describe your results. Are they comparable to scikit-learn's regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, format your data in a DataFrame\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your new statsmodel.formula handling model\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# You can easily swap these out to test multiple versions/different formulas\n",
    "formulas = {\n",
    "    \"case1\": \"MEDV ~ RM + LSTAT + RAD + TAX + NOX + INDUS + CRIM + ZN - 1\", # - 1 = remove intercept\n",
    "    \"case2\": \"MEDV ~ NOX + RM\",\n",
    "    \"case3\": \"MEDV ~ RAD + TAX\"\n",
    "}\n",
    "\n",
    "model = smf.ols(formula=formulas['case1'], data=df)\n",
    "result = model.fit()\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "\n",
    "Can you optimize your R2, selecting the best features? Provide your code and explain your process in a brief written response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "\n",
    "Given a combination of predictors, can you identify another response variable that could be accurately predicted through the exploration of different predictors in this data set?\n",
    "\n",
    "_Tip: Consider pairplots, coefficients, or Pearson scores._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out variable relations\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out Pearson scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS/DEMO: Up for an additional challenge? Try again, this time using the `patsy` library.\n",
    "\n",
    "You can read more about it here: https://patsy.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "# Use the patsy library to run a regression model on the housing dataset\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
